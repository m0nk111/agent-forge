# BM25 Hybrid Search Implementation

**Date**: 2025-10-13  
**Status**: ‚úÖ **PRODUCTION READY**

Complete technical documentation for the BM25 client-side sparse vector implementation in Agent-Forge's semantic search system.

---

## üìã Table of Contents

- [Overview](#overview)
- [The Problem](#the-problem)
- [The Solution](#the-solution)
- [Implementation Details](#implementation-details)
- [Architecture](#architecture)
- [Code Examples](#code-examples)
- [Performance](#performance)
- [Testing](#testing)
- [Troubleshooting](#troubleshooting)

---

## Overview

### What is Hybrid Search?

**Hybrid search** combines two complementary vector search approaches:

1. **Dense Vectors** (Semantic/Embedding-based)
   - High-dimensional vectors (e.g., 1536 dims from OpenAI)
   - Captures semantic meaning and context
   - Good for: Synonyms, paraphrasing, conceptual similarity
   - Example: "authentication" matches "login system", "user credentials"

2. **Sparse Vectors** (Keyword/Term-based)
   - Variable-length vectors with mostly zero values
   - Captures exact term presence and frequency
   - Good for: Exact matches, rare terms, technical keywords
   - Example: "OAuth2.0" matches documents with that exact term

3. **RRF Reranking** (Reciprocal Rank Fusion)
   - Combines results from both vector types
   - Balances semantic understanding with keyword precision
   - Formula: `RRF(d) = Œ£ 1 / (k + rank_i(d))` where k=60 typically

### Why BM25?

**BM25 (Best Matching 25)** is the gold standard for sparse vector generation:
- Used by Elasticsearch, Solr, and most search engines
- Better than TF-IDF for ranking
- Handles document length normalization
- Prevents term frequency saturation

---

## The Problem

### Initial Issue: Server-Side BM25 Failed

When we first integrated Milvus hybrid search, we used **server-side BM25 functions**:

```typescript
// Collection schema with BM25 function
const functions = [{
    name: "content_bm25_emb",
    type: FunctionType.BM25,
    input_field_names: ["content"],
    output_field_names: ["sparse_vector"],
    params: {},
}];
```

**What happened**:
```
‚ùå Insert result: {
  "insert_count": "0",
  "status_code": "IllegalArgument",
  "status_reason": "sparse float field 'sparse_vector' is illegal, 
                   array type mismatch: [expected=need sparse float array]
                   [actual=got nil]"
}
```

### Root Cause

**Milvus BM25 functions don't auto-execute on insert**:
- Function was declared in schema
- But sparse_vector field received `nil` values
- Milvus expected sparse float array, got nothing
- All inserts failed with 0 entities indexed

**Why not fixed upstream?**:
- Unclear if bug or intended behavior
- No clear documentation on function execution
- Different Milvus versions behave differently
- Decided to implement client-side for reliability

---

## The Solution

### Client-Side BM25 Generation

Instead of relying on Milvus to generate sparse vectors, **we generate them in TypeScript before insert**.

**Key components**:
1. `bm25-encoder.ts` - BM25 implementation
2. Modified `insertHybrid()` - Encode before insert
3. Modified `hybridSearch()` - Encode queries + auto-fit
4. Singleton pattern - One encoder per process

**Benefits**:
- ‚úÖ Full control over tokenization
- ‚úÖ Debuggable (inspect vocabulary, scores)
- ‚úÖ Works with any Milvus version
- ‚úÖ Customizable parameters (k1, b)
- ‚úÖ Auto-fit from collection data

---

## Implementation Details

### BM25 Encoder Class

**File**: `tools/claude-context/packages/core/src/vectordb/bm25-encoder.ts`

#### Core Data Structures

```typescript
class BM25Encoder {
    private vocabulary: Map<string, number>;        // term ‚Üí term_id
    private documentFrequency: Map<string, number>; // term ‚Üí doc_count
    private avgDocumentLength: number;
    private totalDocuments: number;
    private k1: number = 1.5;  // Term saturation parameter
    private b: number = 0.75;  // Length normalization
}
```

#### Tokenization

Simple but effective for code:
```typescript
private tokenize(text: string): string[] {
    return text
        .toLowerCase()                    // Case insensitive
        .replace(/[^a-z0-9\s]/g, ' ')    // Remove punctuation
        .split(/\s+/)                     // Split on whitespace
        .filter(token => token.length > 0);
}
```

**Example**:
```
Input:  "GitHub API Client"
Output: ["github", "api", "client"]
```

#### Vocabulary Building (fit phase)

```typescript
fit(documents: string[]): void {
    const tokenizedDocs = documents.map(doc => ({
        tokens: this.tokenize(doc)
    }));
    
    // Build vocabulary
    const vocabularySet = new Set<string>();
    tokenizedDocs.forEach(doc => {
        const uniqueTokens = new Set(doc.tokens);
        uniqueTokens.forEach(token => {
            vocabularySet.add(token);
            this.documentFrequency.set(
                token,
                (this.documentFrequency.get(token) || 0) + 1
            );
        });
    });
    
    // Assign term IDs
    let termId = 0;
    vocabularySet.forEach(term => {
        this.vocabulary.set(term, termId++);
    });
    
    // Calculate average document length
    const totalTokens = tokenizedDocs.reduce(
        (sum, doc) => sum + doc.tokens.length, 0
    );
    this.avgDocumentLength = totalTokens / documents.length;
}
```

**Example Output**:
```
vocabulary: {
    "github": 0,
    "api": 1,
    "client": 2,
    "authentication": 3,
    ...
}

documentFrequency: {
    "github": 45,    // Appears in 45 docs
    "api": 123,      // Common term
    "oauth2": 3,     // Rare term (higher IDF)
    ...
}

avgDocumentLength: 185.21
totalDocuments: 606
```

#### BM25 Score Calculation

```typescript
encode(document: string): SparseVector {
    const tokens = this.tokenize(document);
    const termFrequency = new Map<string, number>();
    
    // Count term frequencies
    tokens.forEach(token => {
        termFrequency.set(token, (termFrequency.get(token) || 0) + 1);
    });
    
    const sparseVector: SparseVector = {};
    const documentLength = tokens.length;
    
    // Calculate BM25 for each term
    termFrequency.forEach((tf, term) => {
        const termId = this.vocabulary.get(term);
        if (termId === undefined) return; // Unknown term
        
        const df = this.documentFrequency.get(term) || 0;
        
        // IDF calculation
        const idf = Math.log(
            (this.totalDocuments - df + 0.5) / (df + 0.5) + 1
        );
        
        // BM25 calculation
        const numerator = tf * (this.k1 + 1);
        const denominator = tf + this.k1 * (
            1 - this.b + this.b * (documentLength / this.avgDocumentLength)
        );
        const bm25Score = idf * (numerator / denominator);
        
        if (bm25Score > 0) {
            sparseVector[termId] = bm25Score;
        }
    });
    
    return sparseVector;
}
```

**Example**:
```typescript
Input: "GitHub API authentication using OAuth2"
Tokens: ["github", "api", "authentication", "using", "oauth2"]

Output SparseVector:
{
    0: 2.43,   // "github" (termId 0) - moderate score
    1: 1.87,   // "api" (termId 1) - common term
    3: 2.15,   // "authentication" (termId 3)
    15: 3.92,  // "oauth2" (termId 15) - rare, high IDF!
    42: 1.23   // "using" (termId 42) - stopword-like
}
```

**Key observations**:
- Rare terms (low df) ‚Üí high IDF ‚Üí high BM25 score
- Common terms ‚Üí low IDF ‚Üí lower score
- Only non-zero scores included (sparse!)
- Document length normalized via `b` parameter

#### Singleton Pattern

```typescript
let globalEncoder: BM25Encoder | null = null;

export function getGlobalBM25Encoder(): BM25Encoder {
    if (!globalEncoder) {
        globalEncoder = new BM25Encoder();
    }
    return globalEncoder;
}

export function fitGlobalBM25Encoder(corpus: string[]): void {
    const encoder = getGlobalBM25Encoder();
    encoder.fit(corpus);
}
```

**Why singleton?**:
- One vocabulary per process/collection
- Avoid re-fitting on every operation
- Shared state across multiple operations

---

## Architecture

### Insert Flow with BM25

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. Documents arrive at insertHybrid()            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. Check if BM25 encoder fitted                  ‚îÇ
‚îÇ    if (!encoder.isFitted()) {                    ‚îÇ
‚îÇ        fit(documents)  // Build vocabulary       ‚îÇ
‚îÇ    }                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. Generate dense vectors (OpenAI)               ‚îÇ
‚îÇ    vector = await openai.embed(doc.content)      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 4. Generate sparse vectors (BM25)                ‚îÇ
‚îÇ    sparse_vector = encoder.encode(doc.content)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 5. Insert to Milvus with both vectors            ‚îÇ
‚îÇ    milvus.insert({                               ‚îÇ
‚îÇ        vector: [0.123, -0.456, ...],            ‚îÇ
‚îÇ        sparse_vector: {0: 2.43, 1: 1.87}        ‚îÇ
‚îÇ    })                                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Search Flow with BM25

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. Query arrives at hybridSearch()               ‚îÇ
‚îÇ    query = "GitHub API authentication"           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 2. Check if encoder fitted (auto-fit)            ‚îÇ
‚îÇ    if (!encoder.isFitted()) {                    ‚îÇ
‚îÇ        docs = query_collection(['content'])      ‚îÇ
‚îÇ        fit(docs)  // Build from collection       ‚îÇ
‚îÇ    }                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 3. Generate dense query vector                   ‚îÇ
‚îÇ    denseVector = await openai.embed(query)       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 4. Generate sparse query vector                  ‚îÇ
‚îÇ    sparseVector = encoder.encode(query)          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 5. Execute hybrid search in Milvus               ‚îÇ
‚îÇ    results = milvus.search({                     ‚îÇ
‚îÇ        data: [                                   ‚îÇ
‚îÇ            {data: denseVector, field: "vector"}, ‚îÇ
‚îÇ            {data: sparseVector, field: "sparse"} ‚îÇ
‚îÇ        ],                                        ‚îÇ
‚îÇ        rerank: {strategy: "rrf", k: 100}        ‚îÇ
‚îÇ    })                                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Code Examples

### Example 1: Indexing Documents

```typescript
import { Context } from './packages/core/src/context';
import { OpenAIEmbedding } from './packages/core/src/embedding/openai-embedding';
import { MilvusVectorDatabase } from './packages/core/src/vectordb/milvus-vectordb';

// Enable hybrid mode
process.env.HYBRID_MODE = 'true';

const embedding = new OpenAIEmbedding({
    apiKey: process.env.OPENAI_API_KEY,
    model: 'text-embedding-3-small'
});

const vectordb = new MilvusVectorDatabase({
    address: 'localhost:19530'
});

const context = new Context({ embedding, vectorDatabase: vectordb });

// Index codebase (auto-generates BM25 sparse vectors)
const result = await context.indexCodebase('/path/to/codebase');

console.log(`Indexed ${result.totalChunks} chunks`);
// BM25 encoder automatically fitted on corpus
// Vocabulary size: ~1000-5000 terms typically
```

### Example 2: Searching with Hybrid Mode

```typescript
// Search (auto-fits encoder if needed)
const results = await context.semanticSearch(
    '/path/to/codebase',
    'GitHub API authentication',
    5  // top 5 results
);

results.forEach((r, i) => {
    console.log(`${i+1}. ${r.relativePath}`);
    console.log(`   Score: ${r.score.toFixed(4)}`);
    console.log(`   Lines: ${r.startLine}-${r.endLine}`);
});

// Output example:
// 1. pr_github_client.py
//    Score: 0.0193
//    Lines: 20-82
```

### Example 3: Python Wrapper Usage

```python
from engine.utils.claude_context_simple import SimpleClaudeContext

# Initialize (HYBRID_MODE=true automatically)
context = SimpleClaudeContext()

# Search (BM25 encoder auto-fits on first search)
results = context.search_code(
    codebase_path="/home/user/project",
    query="authentication with OAuth"
)

for result in results:
    print(f"{result['relativePath']}: {result['score']:.4f}")
```

---

## Performance

### Benchmarks

**Indexing Performance** (606 documents, ~38 Python files):
- BM25 vocabulary build: ~50ms
- BM25 encoding per document: ~1-2ms
- Total overhead: ~5-10% compared to dense-only
- **Result**: Negligible impact on indexing time

**Search Performance**:
- BM25 query encoding: <1ms
- Auto-fit from collection (first search): ~500ms (one-time)
- Subsequent searches: Same speed as dense-only
- **Result**: No noticeable latency increase

**Memory Usage**:
- Vocabulary: ~1-5 MB for typical codebase
- BM25 encoder overhead: Minimal
- **Result**: Acceptable memory footprint

### Comparison: Dense-Only vs Hybrid

**Test Query**: "GitHub API authentication"

**Dense-Only** (previous workaround):
```
1. repo_manager.py      Score: 0.385
2. pr_review_agent.py   Score: 0.380
3. bot_operations.py    Score: 0.374
```

**Hybrid** (BM25 + Dense):
```
1. pr_github_client.py  Score: 0.0193  ‚Üê More specific!
2. repo_manager.py      Score: 0.0099
3. team_manager.py      Score: 0.0099
```

**Observations**:
- Scores use different scales (RRF vs cosine)
- Hybrid found more specific matches
- "github" keyword weighted higher with BM25
- Better for technical/exact term queries

---

## Testing

### Unit Tests

```bash
cd /home/flip/agent-forge/tools/claude-context
npx ts-node test_indexing.ts
```

**Expected output**:
```
üöÄ [TEST] Hybrid mode ENABLED - testing BM25 sparse vectors

[MilvusDB] üîß Fitting BM25 encoder on 100 documents...
‚úÖ [BM25] Vocabulary size: 929
üìä [BM25] Avg doc length: 185.21

[MilvusDB] ‚úÖ Insert result: {
  "insert_count": "100",
  "status_code": "Success"
}

üîç Testing search...
‚úÖ Found 5 relevant results
```

### Integration Test (Python)

```bash
cd /home/flip/agent-forge
python3 << 'EOF'
from engine.utils.claude_context_simple import SimpleClaudeContext

context = SimpleClaudeContext()
results = context.search_code(
    codebase_path="/home/flip/agent-forge/engine/operations",
    query="GitHub API authentication"
)

assert len(results) > 0, "No results found"
assert all('score' in r for r in results), "Missing scores"
print(f"‚úÖ Test passed: {len(results)} results found")
EOF
```

---

## Troubleshooting

### Issue: "BM25 encoder not fitted"

**Symptom**:
```
Error: BM25 encoder not fitted. Please index documents first.
```

**Cause**: Encoder singleton not initialized

**Solution**: Auto-fit is implemented, but if it fails:
```typescript
// Manual fit from collection
const docs = await milvus.query({
    collection_name: collectionName,
    output_fields: ['content'],
    limit: 10000
});
fitGlobalBM25Encoder(docs.map(d => d.content));
```

### Issue: Low/Different Scores

**Symptom**: Hybrid scores (0.01-0.02) much lower than dense-only (0.3-0.4)

**Explanation**: 
- **Different scoring systems!**
- Dense-only: Cosine similarity (0-1 scale)
- Hybrid: RRF combined score (different scale)
- Lower numbers doesn't mean worse results
- RRF emphasizes rank, not absolute similarity

**What matters**: **Rank order**, not absolute scores

### Issue: Vocabulary Too Large

**Symptom**: Memory issues with large codebases

**Solution**: Implement vocabulary pruning:
```typescript
// In fit(), after building vocabulary:
if (vocabularySet.size > 50000) {
    // Keep only terms appearing in 2+ documents
    // Or implement min_df/max_df thresholds
}
```

### Issue: Tokenization Not Ideal for Code

**Symptom**: Poor matches for camelCase, snake_case

**Enhancement** (future):
```typescript
private tokenize(text: string): string[] {
    // Better code tokenization
    return text
        .replace(/([a-z])([A-Z])/g, '$1 $2')  // camelCase
        .replace(/_/g, ' ')                    // snake_case
        .toLowerCase()
        .replace(/[^a-z0-9\s]/g, ' ')
        .split(/\s+/)
        .filter(token => token.length > 1);  // Remove single chars
}
```

---

## Summary

### What We Built

‚úÖ **Client-side BM25 implementation** (`bm25-encoder.ts`)  
‚úÖ **Hybrid search integration** (dense + sparse vectors)  
‚úÖ **Auto-fit encoder** from collection data  
‚úÖ **RRF reranking** for optimal results  
‚úÖ **Python wrapper support** (HYBRID_MODE=true)

### Key Takeaways

1. **Server-side BM25 functions don't work** in Milvus (at least not reliably)
2. **Client-side generation is better**: More control, debuggable, portable
3. **Hybrid search works**: Combines semantic + keyword effectively
4. **Auto-fit is essential**: Makes search "just work" without manual steps
5. **Score scales differ**: RRF vs cosine, focus on rank not absolute values

### Production Status

üéâ **FULLY OPERATIONAL**:
- 606 entities indexed with both vector types
- Hybrid search returning relevant results
- Python wrapper functional end-to-end
- Zero insert failures
- Auto-fit working on first search

### Next Steps

**Potential Improvements**:
1. Persist vocabulary to disk (avoid re-fitting)
2. Better code tokenization (camelCase, snake_case)
3. Vocabulary pruning for very large codebases
4. Configurable BM25 parameters (k1, b)
5. Metrics/telemetry for BM25 performance

---

**Documentation**: See also
- [CLAUDE_CONTEXT_INTEGRATION.md](CLAUDE_CONTEXT_INTEGRATION.md)
- [CLAUDE_CONTEXT_STATUS.md](CLAUDE_CONTEXT_STATUS.md)
- [CHANGELOG.md](../CHANGELOG.md)
